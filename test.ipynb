{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f55fd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import typing as t\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "\n",
    "from aiida import load_profile, orm\n",
    "from aiida_quantumespresso.calculations.pp import PpCalculation\n",
    "from aiida_quantumespresso.workflows.pw.base import PwBaseWorkChain\n",
    "from aiida_quantumespresso.workflows.pw.relax import PwRelaxWorkChain\n",
    "from aiida_workgraph import dynamic, namespace, shelljob, task\n",
    "from ase import Atoms\n",
    "\n",
    "_ = load_profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099e7ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AfmCase(Enum):\n",
    "    EMPIRICAL = 1\n",
    "    HARTREE = 2\n",
    "    HARTREE_RHO = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ed1620",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def write_afm_params(params: dict) -> orm.SinglefileData:\n",
    "    afm_filepath = Path.cwd() / \"params.ini\"\n",
    "    with open(afm_filepath, \"w\") as config_file:\n",
    "        for key, value in params.items():\n",
    "            if isinstance(value, (list, tuple)):\n",
    "                value = \" \".join(map(str, value))\n",
    "            config_file.write(f\"{key} {value}\\n\")\n",
    "    return orm.SinglefileData(file=afm_filepath.as_posix())\n",
    "\n",
    "\n",
    "@task\n",
    "def write_structure_file(structure: Atoms) -> orm.SinglefileData:\n",
    "    geom_filepath = Path.cwd() / \"geo.xyz\"\n",
    "    structure.write(geom_filepath, format=\"xyz\")\n",
    "    return orm.SinglefileData(file=geom_filepath.as_posix())\n",
    "\n",
    "RelaxJob = task(PwRelaxWorkChain)\n",
    "ScfJob = task(PwBaseWorkChain)\n",
    "PpJob = task(PpCalculation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14892d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import typing as t\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "\n",
    "from aiida import orm\n",
    "from aiida_quantumespresso.calculations.pp import PpCalculation\n",
    "from aiida_quantumespresso.workflows.pw.base import PwBaseWorkChain\n",
    "from aiida_quantumespresso.workflows.pw.relax import PwRelaxWorkChain\n",
    "from aiida_workgraph import dynamic, namespace, shelljob, task\n",
    "from ase import Atoms\n",
    "\n",
    "\n",
    "class AfmCase(Enum):\n",
    "    EMPIRICAL = \"empirical\"\n",
    "    HARTREE = \"hartree\"\n",
    "    HARTREE_RHO = \"hartree_rho\"\n",
    "\n",
    "\n",
    "@task\n",
    "def write_afm_params(params: dict) -> orm.SinglefileData:\n",
    "    afm_filepath = Path.cwd() / \"params.ini\"\n",
    "    with open(afm_filepath, \"w\") as config_file:\n",
    "        for key, value in params.items():\n",
    "            if isinstance(value, (list, tuple)):\n",
    "                value = \" \".join(map(str, value))\n",
    "            config_file.write(f\"{key} {value}\\n\")\n",
    "    return orm.SinglefileData(file=afm_filepath.as_posix())\n",
    "\n",
    "\n",
    "@task\n",
    "def write_structure_file(structure: Atoms) -> orm.SinglefileData:\n",
    "    geom_filepath = Path.cwd() / \"geo.xyz\"\n",
    "    structure.write(geom_filepath, format=\"xyz\")\n",
    "    return orm.SinglefileData(file=geom_filepath.as_posix())\n",
    "\n",
    "\n",
    "RelaxationJob = task(PwRelaxWorkChain)\n",
    "ScfJob = task(PwBaseWorkChain)\n",
    "PpJob = task(PpCalculation)\n",
    "\n",
    "\n",
    "@task.graph\n",
    "def AfmWorkflow(\n",
    "    case: AfmCase,\n",
    "    structure: orm.StructureData,\n",
    "    afm_params: dict,\n",
    "    relax: bool = False,\n",
    "    dft_params: t.Annotated[\n",
    "        dict,\n",
    "        RelaxationJob.inputs,\n",
    "    ] = None,\n",
    "    pp_params: t.Annotated[\n",
    "        dict,\n",
    "        namespace(\n",
    "            hartree=PpJob.inputs,\n",
    "            charge=namespace(\n",
    "                structure=PpJob.inputs,\n",
    "                tip=PpJob.inputs,\n",
    "            ),\n",
    "        ),\n",
    "    ] = None,\n",
    "    tip: orm.StructureData = None,\n",
    ") -> t.Annotated[dict, dynamic(t.Any)]:\n",
    "    \"\"\"AFM simulation workflow.\"\"\"\n",
    "\n",
    "    dft_task = None\n",
    "    hartree_task = None\n",
    "    rho_task = None\n",
    "    tip_rho_task = None\n",
    "\n",
    "    if relax:\n",
    "        assert dft_params, \"Missing DFT parameters\"\n",
    "        dft_task = RelaxationJob(\n",
    "            structure=structure,\n",
    "            **dft_params,\n",
    "        )\n",
    "        structure = dft_task.output_structure\n",
    "\n",
    "    assert structure, \"Missing structure\"\n",
    "    geometry_file = write_structure_file(structure=structure).result\n",
    "\n",
    "    assert afm_params, \"Missing AFM parameters\"\n",
    "    afm_params_file = write_afm_params(params=afm_params).result\n",
    "\n",
    "    ljff = shelljob(\n",
    "        command=\"ppafm-generate-ljff\",\n",
    "        nodes={\n",
    "            \"geometry\": geometry_file,\n",
    "            \"parameters\": afm_params_file,\n",
    "        },\n",
    "        arguments=[\n",
    "            \"-i\",\n",
    "            \"geo.xyz\",\n",
    "            \"-f\",\n",
    "            \"npy\",\n",
    "        ],\n",
    "        outputs=[\"FFLJ.npz\"],\n",
    "    )\n",
    "\n",
    "    scan_nodes = {\n",
    "        \"parameters\": afm_params_file,\n",
    "        \"ljff_data\": ljff.FFLJ_npz,\n",
    "    }\n",
    "\n",
    "    metadata = {\n",
    "        \"options\": {\n",
    "            \"use_symlinks\": True,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if case != AfmCase.EMPIRICAL:\n",
    "        if not relax:\n",
    "            assert dft_params, \"Missing DFT parameters\"\n",
    "            scf_params = dft_params.get(\"base\", {})\n",
    "            assert scf_params, \"Missing base SCF parameters\"\n",
    "            scf_params[\"pw.structure\"] = structure\n",
    "            dft_task = ScfJob(**scf_params)\n",
    "\n",
    "        assert pp_params, \"Missing post-processing parameters\"\n",
    "        hartree_params = pp_params.get(\"hartree\", {})\n",
    "        assert hartree_params, \"Missing Hartree parameters\"\n",
    "        hartree_task = PpJob(\n",
    "            parent_folder=dft_task.remote_folder,\n",
    "            **hartree_params,\n",
    "        )\n",
    "\n",
    "        if case == AfmCase.HARTREE.name:\n",
    "            elff = shelljob(\n",
    "                command=\"ppafm-generate-elff\",\n",
    "                metadata=metadata,\n",
    "                nodes={\n",
    "                    \"parameters\": afm_params_file,\n",
    "                    \"ljff_data\": ljff.FFLJ_npz,\n",
    "                    \"hartree_data\": hartree_task.remote_folder,\n",
    "                },\n",
    "                filenames={\n",
    "                    \"hartree_data\": \"hartree\",\n",
    "                },\n",
    "                arguments=[\n",
    "                    \"-i\",\n",
    "                    \"hartree/aiida.fileout\",\n",
    "                    \"-F\",\n",
    "                    \"cube\",\n",
    "                    \"-f\",\n",
    "                    \"npy\",\n",
    "                ],\n",
    "                outputs=[\"FFel.npz\"],\n",
    "            )\n",
    "\n",
    "            scan_nodes[\"elff_data\"] = elff.FFel_npz\n",
    "\n",
    "        # Experimental feature, not fully tested\n",
    "        elif case == AfmCase.HARTREE_RHO:\n",
    "            charge_namespace: dict = pp_params.get(\"charge\", {})\n",
    "            geom_charge_params = charge_namespace.get(\"structure\", {})\n",
    "            assert geom_charge_params, \"Missing structure charge density parameters\"\n",
    "            rho_task = PpJob(\n",
    "                structure=structure,\n",
    "                parent_folder=dft_task.remote_folder,\n",
    "                **geom_charge_params,\n",
    "            )\n",
    "\n",
    "            # write tip file\n",
    "\n",
    "            tip_charge_params = charge_namespace.get(\"tip\", {})\n",
    "            assert tip, \"Missing tip structure\"\n",
    "            assert tip_charge_params, \"Missing tip charge density parameters\"\n",
    "            tip_rho_task = PpJob(\n",
    "                structure=tip,\n",
    "                parent_folder=dft_task.remote_folder,\n",
    "                **tip_charge_params,\n",
    "            )\n",
    "\n",
    "            conv_rho = shelljob(\n",
    "                command=\"ppafm-conv-rho\",\n",
    "                nodes={\n",
    "                    \"geom_density\": rho_task.remote_folder,\n",
    "                    \"tip_density\": tip_rho_task.remote_folder,\n",
    "                },\n",
    "                filenames={\n",
    "                    \"geom_density\": \"structure\",\n",
    "                    \"tip_density\": \"tip\",\n",
    "                },\n",
    "                arguments=[\n",
    "                    \"-s\",\n",
    "                    \"structure/charge.cube\",\n",
    "                    \"-t\",\n",
    "                    \"tip/charge.cube\",\n",
    "                    \"-B\",\n",
    "                    \"1.0\",\n",
    "                    \"-E\",\n",
    "                ],\n",
    "                outputs=[\"charge.cube\"],\n",
    "            )\n",
    "\n",
    "            charge_elff = shelljob(\n",
    "                command=\"ppafm-generate-elff\",\n",
    "                nodes={\n",
    "                    \"hartree_data\": hartree_task.remote_folder,\n",
    "                    \"conv_density\": conv_rho.charge_cube,\n",
    "                    \"tip_density\": tip_rho_task.remote_folder,\n",
    "                },\n",
    "                filenames={\n",
    "                    \"hartree_data\": \"hartree\",\n",
    "                    \"tip_density\": \"tip\",\n",
    "                },\n",
    "                arguments=[\n",
    "                    \"-i\",\n",
    "                    \"hartree/hartree.cube\",\n",
    "                    \"-tip-dens\",\n",
    "                    \"tip/charge.cube\",\n",
    "                    \"--Rcode\",\n",
    "                    \"0.7\",\n",
    "                    \"-E\",\n",
    "                    \"--doDensity\",\n",
    "                ],\n",
    "                outputs=[\"FFel.npz\"],\n",
    "            )\n",
    "\n",
    "            dftd3 = shelljob(\n",
    "                command=\"ppafm-generate-dftd3\",\n",
    "                nodes={\n",
    "                    \"hartree_data\": hartree_task.remote_folder,\n",
    "                },\n",
    "                filenames={\n",
    "                    \"hartree_data\": \"hartree\",\n",
    "                },\n",
    "                arguments=[\n",
    "                    \"-i\",\n",
    "                    \"hartree/hartree.cube\",\n",
    "                    \"--df_name\",\n",
    "                    \"PBE\",\n",
    "                ],\n",
    "                outputs=[\"dftd3.dat\"],\n",
    "            )\n",
    "\n",
    "            elff = shelljob(\n",
    "                command=\"ppafm-generate-elff\",\n",
    "                nodes={\n",
    "                    \"hartree_data\": hartree_task.remote_folder,\n",
    "                    \"charge_elff_data\": charge_elff.FFel_npz,\n",
    "                    \"dftd3_data\": dftd3.dftd3_dat,\n",
    "                },\n",
    "                arguments=[\n",
    "                    \"-i\",\n",
    "                    \"hartree/hartree.cube\",\n",
    "                    \"-f\",\n",
    "                    \"npy\",\n",
    "                ],\n",
    "                outputs=[\"FFel.npz\"],\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported case: {case}\")\n",
    "\n",
    "    scan = shelljob(\n",
    "        command=\"ppafm-relaxed-scan\",\n",
    "        metadata=metadata,\n",
    "        nodes=scan_nodes,\n",
    "        arguments=[\n",
    "            \"-f\",\n",
    "            \"npy\",\n",
    "        ],\n",
    "        outputs=[\"Q0.00K0.35\"],\n",
    "    )\n",
    "\n",
    "    results = shelljob(\n",
    "        command=\"ppafm-plot-results\",\n",
    "        metadata=metadata,\n",
    "        nodes={\n",
    "            \"parameters\": afm_params_file,\n",
    "            \"scan_dir\": scan.Q0_00K0_35,\n",
    "        },\n",
    "        filenames={\n",
    "            \"scan_dir\": \"Q0.00K0.35\",\n",
    "        },\n",
    "        arguments=[\n",
    "            \"--df\",\n",
    "            \"--cbar\",\n",
    "            \"--save_df\",\n",
    "            \"-f\",\n",
    "            \"npy\",\n",
    "        ],\n",
    "        outputs=[\"Q0.00K0.35\"],\n",
    "    )\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c0a2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_pseudo.groups.family.pseudo import PseudoPotentialFamily\n",
    "\n",
    "structure = orm.StructureData()\n",
    "structure.set_cell([[10.0, 0.0, 0.0], [0.0, 10.0, 0.0], [0.0, 0.0, 10.0]])\n",
    "structure.set_pbc((False, False, False))\n",
    "structure.append_atom(symbols=\"C\", position=(8.2766055186, 6.1177492411, 5.0595246063))\n",
    "structure.append_atom(symbols=\"C\", position=(8.8582363932, 7.3839854920, 5.0363959612))\n",
    "structure.append_atom(symbols=\"C\", position=(8.0523006568, 8.5208073256, 5.0178902940))\n",
    "structure.append_atom(symbols=\"C\", position=(6.6646772714, 8.3913773689, 5.0224782237))\n",
    "structure.append_atom(symbols=\"C\", position=(6.0830463468, 7.1251409580, 5.0456056988))\n",
    "structure.append_atom(symbols=\"C\", position=(6.8889822232, 5.9883191444, 5.0641114560))\n",
    "structure.append_atom(symbols=\"H\", position=(8.9093056269, 5.2253257080, 5.0739448106))\n",
    "structure.append_atom(symbols=\"H\", position=(9.9475591624, 7.4856249613, 5.0328185108))\n",
    "structure.append_atom(symbols=\"H\", position=(8.5089059407, 9.5148483491, 4.9998780126))\n",
    "structure.append_atom(symbols=\"H\", position=(6.0319773431, 9.2838011020, 5.0080584394))\n",
    "structure.append_atom(symbols=\"H\", position=(4.9937235476, 7.0235011287, 5.0491811392))\n",
    "structure.append_atom(symbols=\"H\", position=(6.4323774593, 4.9942778709, 5.0821221574))\n",
    "\n",
    "kpoints = orm.KpointsData()\n",
    "kpoints.set_kpoints_mesh([1, 1, 1])\n",
    "\n",
    "pseudo_family = t.cast(PseudoPotentialFamily, orm.load_group(4))\n",
    "C_pp = pseudo_family.get_pseudo(\"C\")\n",
    "H_pp = pseudo_family.get_pseudo(\"H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c626df",
   "metadata": {},
   "outputs": [],
   "source": [
    "afm_params = {\n",
    "    \"PBC\": False,\n",
    "    \"tip\": \"s\",\n",
    "    \"klat\": 0.3490127886809,\n",
    "    \"krad\": 21.913190531846,\n",
    "    \"gridA\": [14.9412827110, 0.0000000000, 0.0000000000],\n",
    "    \"gridB\": [0.0000000000, 14.5091262213, 0.0000000000],\n",
    "    \"gridC\": [0.0000000000, 0.0000000000, 10.0820001747],\n",
    "    \"sigma\": 0.7,\n",
    "    \"charge\": 0.0,\n",
    "    \"r0Probe\": [0.0, 0.0, 2.97],\n",
    "    \"scanMax\": [14.9412827110, 14.5091262213, 11],\n",
    "    \"scanMin\": [0.0, 0.0, 8],\n",
    "    \"scanStep\": [0.1, 0.1, 0.1],\n",
    "    \"Amplitude\": 1.4,\n",
    "    \"probeType\": \"O\",\n",
    "    \"f0Cantilever\": 22352.5,\n",
    "    \"gridN\": [-1, -1, -1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf33e88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft_params = {\n",
    "    \"base\": {\n",
    "        \"metadata\": {},\n",
    "        \"pw\": {\n",
    "            \"metadata\": {\n",
    "                \"options\": {\n",
    "                    \"resources\": {\n",
    "                        \"num_machines\": 1,\n",
    "                    },\n",
    "                    \"max_wallclock_seconds\": 43200,\n",
    "                }\n",
    "            },\n",
    "            \"pseudos\": {\n",
    "                \"C\": C_pp,\n",
    "                \"H\": H_pp,\n",
    "            },\n",
    "            \"code\": orm.load_code(\"pw-7.4@localhost\"),\n",
    "            \"parameters\": {\n",
    "                \"CONTROL\": {\n",
    "                    \"calculation\": \"relax\",\n",
    "                    \"forc_conv_thr\": 0.001,\n",
    "                    \"tprnfor\": True,\n",
    "                    \"tstress\": True,\n",
    "                    \"etot_conv_thr\": 0.0002,\n",
    "                    \"nstep\": 50,\n",
    "                },\n",
    "                \"SYSTEM\": {\n",
    "                    \"nosym\": False,\n",
    "                    \"occupations\": \"fixed\",\n",
    "                    \"ecutrho\": 240.0,\n",
    "                    \"ecutwfc\": 30.0,\n",
    "                    \"tot_charge\": 0.0,\n",
    "                    \"vdw_corr\": \"none\",\n",
    "                },\n",
    "                \"ELECTRONS\": {\n",
    "                    \"electron_maxstep\": 80,\n",
    "                    \"mixing_beta\": 0.4,\n",
    "                    \"conv_thr\": 8e-10,\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        \"kpoints\": kpoints,\n",
    "        \"kpoints_force_parity\": False,\n",
    "        \"max_iterations\": 5,\n",
    "    },\n",
    "    \"max_meta_convergence_iterations\": 5,\n",
    "    \"meta_convergence\": True,\n",
    "    \"volume_convergence\": 0.05,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7ffea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_params = {\n",
    "    \"hartree\": {\n",
    "        \"metadata\": {\n",
    "            \"options\": {\n",
    "                \"resources\": {\n",
    "                    \"num_machines\": 1,\n",
    "                },\n",
    "                \"max_wallclock_seconds\": 43200,\n",
    "            }\n",
    "        },\n",
    "        \"code\": orm.load_code(\"pp-7.4@localhost\"),\n",
    "        \"parameters\": {\n",
    "            \"INPUTPP\": {\n",
    "                \"plot_num\": 11,\n",
    "            },\n",
    "            \"PLOT\": {\n",
    "                \"iflag\": 3,\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"charge\": {\n",
    "        \"structure\": {},\n",
    "        \"tip\": {},\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7823b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg = AfmWorkflow.build(\n",
    "    case=AfmCase.HARTREE.name,\n",
    "    structure=structure,\n",
    "    afm_params=afm_params,\n",
    "    relax=False,\n",
    "    dft_params=dft_params,\n",
    "    pp_params=pp_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9176b761",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baa60aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a2c94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = orm.load_node(wg.pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50fa794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "fd: orm.FolderData = node.outputs.Q0_00K0_35\n",
    "\n",
    "imgs = []\n",
    "\n",
    "png_folder = \"Amp1.40\"\n",
    "\n",
    "for obj in fd.list_objects(png_folder):\n",
    "    if obj.name.endswith(\".png\"):\n",
    "        with fd.open(f\"{png_folder}/{obj.name}\", \"rb\") as handle:\n",
    "            data = handle.read()\n",
    "            data64 = base64.b64encode(data).decode(\"utf-8\")\n",
    "            imgs.append(f\"\"\"\n",
    "                <img\n",
    "                    src=\"data:image/png;base64,{data64}\"\n",
    "                    style=\"max-width:150px; margin:5px;\"\n",
    "                />\n",
    "            \"\"\")\n",
    "\n",
    "HTML(\"\".join(imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ef5392",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
