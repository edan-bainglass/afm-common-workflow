{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f55fd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as t\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "from aiida import engine, load_profile, orm\n",
    "from aiida_workgraph import dynamic, namespace, shelljob, task\n",
    "from aiida_workgraph.utils import get_dict_from_builder\n",
    "from ase import Atoms\n",
    "\n",
    "_ = load_profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c709522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_common_workflows.plugins import WorkflowFactory\n",
    "from aiida_common_workflows.workflows.pp.workchain import CommonPostProcessWorkChain\n",
    "from aiida_common_workflows.workflows.relax.workchain import CommonRelaxWorkChain\n",
    "\n",
    "CommonRelaxWorkChain._process_class = engine.Process\n",
    "CommonPostProcessWorkChain._process_class = engine.Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ed1620",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AfmCase(Enum):\n",
    "    EMPIRICAL = \"empirical\"\n",
    "    HARTREE = \"hartree\"\n",
    "    HARTREE_RHO = \"hartree_rho\"\n",
    "\n",
    "\n",
    "@task\n",
    "def write_afm_params(params: dict) -> orm.SinglefileData:\n",
    "    with TemporaryDirectory() as tmpdir:\n",
    "        afm_filepath = Path(tmpdir) / \"params.ini\"\n",
    "        with open(afm_filepath, \"w\") as config_file:\n",
    "            for key, value in params.items():\n",
    "                if isinstance(value, (list, tuple)):\n",
    "                    value = \" \".join(map(str, value))\n",
    "                config_file.write(f\"{key} {value}\\n\")\n",
    "        return orm.SinglefileData(file=afm_filepath.as_posix())\n",
    "\n",
    "\n",
    "@task\n",
    "def write_structure_file(structure: Atoms, filename: str) -> orm.SinglefileData:\n",
    "    with TemporaryDirectory() as tmpdir:\n",
    "        geom_filepath = Path(tmpdir) / filename\n",
    "        structure.write(geom_filepath, format=\"xyz\")\n",
    "        return orm.SinglefileData(file=geom_filepath.as_posix())\n",
    "\n",
    "\n",
    "@task.graph\n",
    "def DftJob(\n",
    "    engine: str,\n",
    "    structure: orm.StructureData,\n",
    "    parameters: t.Annotated[\n",
    "        dict,\n",
    "        namespace(\n",
    "            engines=namespace(\n",
    "                relax=namespace(\n",
    "                    code=orm.Code,\n",
    "                    options=dict,\n",
    "                ),\n",
    "            ),\n",
    "            protocol=str,\n",
    "            relax_type=str,\n",
    "        ),\n",
    "    ],\n",
    ") -> t.Annotated[\n",
    "    dict,\n",
    "    task(CommonRelaxWorkChain).outputs,\n",
    "]:\n",
    "    workflow = WorkflowFactory(f\"common_workflows.relax.{engine.value}\")\n",
    "    input_generator = workflow.get_input_generator()\n",
    "    parameters[\"protocol\"] = parameters[\"protocol\"].value\n",
    "    parameters[\"relax_type\"] = parameters[\"relax_type\"].value\n",
    "    parameters[\"engines\"][\"relax\"][\"options\"] = parameters[\"engines\"][\"relax\"][\"options\"].value\n",
    "    builder = input_generator.get_builder(structure=structure, **parameters)\n",
    "    return task(builder._process_class)(**get_dict_from_builder(builder))\n",
    "\n",
    "\n",
    "@task.graph\n",
    "def PpJob(\n",
    "    engine: str,\n",
    "    parent_folder: orm.RemoteData,\n",
    "    parameters: t.Annotated[\n",
    "        dict,\n",
    "        namespace(\n",
    "            engines=namespace(\n",
    "                pp=namespace(\n",
    "                    code=orm.Code,\n",
    "                    options=dict,\n",
    "                ),\n",
    "            ),\n",
    "            quantity=str,\n",
    "        ),\n",
    "    ],\n",
    ") -> t.Annotated[\n",
    "    dict,\n",
    "    task(CommonPostProcessWorkChain).outputs,\n",
    "]:\n",
    "    workflow = WorkflowFactory(f\"common_workflows.pp.{engine.value}\")\n",
    "    input_generator = workflow.get_input_generator()\n",
    "    parameters[\"quantity\"] = parameters[\"quantity\"].value\n",
    "    parameters[\"engines\"][\"pp\"][\"options\"] = parameters[\"engines\"][\"pp\"][\"options\"].value\n",
    "    builder = input_generator.get_builder(parent_folder=parent_folder, **parameters)\n",
    "    return task(builder._process_class)(**get_dict_from_builder(builder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c5d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task.graph\n",
    "def AfmWorkflow(\n",
    "    engine: str,\n",
    "    case: AfmCase,\n",
    "    structure: orm.StructureData,\n",
    "    afm_params: dict,\n",
    "    relax: bool = False,\n",
    "    dft_params: t.Annotated[\n",
    "        dict[str, dict],\n",
    "        namespace(\n",
    "            geom=t.Annotated[\n",
    "                dict,\n",
    "                DftJob.inputs.parameters,\n",
    "            ],\n",
    "            tip=t.Annotated[\n",
    "                dict,\n",
    "                DftJob.inputs.parameters,\n",
    "            ],\n",
    "        ),\n",
    "    ] = None,\n",
    "    pp_params: t.Annotated[\n",
    "        dict[str, dict],\n",
    "        namespace(\n",
    "            hartree_potential=t.Annotated[\n",
    "                dict,\n",
    "                PpJob.inputs.parameters,\n",
    "            ],\n",
    "            charge_density=t.Annotated[\n",
    "                dict,\n",
    "                PpJob.inputs.parameters,\n",
    "            ],\n",
    "        ),\n",
    "    ] = None,\n",
    "    tip: orm.StructureData = None,\n",
    ") -> t.Annotated[dict, dynamic(t.Any)]:\n",
    "    \"\"\"AFM simulation workflow.\"\"\"\n",
    "    if relax:\n",
    "        assert dft_params, \"Missing DFT parameters\"\n",
    "        geom_dft_params = dft_params.get(\"geom\", {})\n",
    "        dft_job = DftJob(\n",
    "            engine=engine,\n",
    "            structure=structure,\n",
    "            parameters=geom_dft_params,\n",
    "        )\n",
    "        structure = dft_job.relaxed_structure\n",
    "    else:\n",
    "        assert structure, \"Missing structure\"\n",
    "\n",
    "    geometry_file = write_structure_file(structure, \"geo.xyz\").result\n",
    "\n",
    "    assert afm_params, \"Missing AFM parameters\"\n",
    "    afm_params_file = write_afm_params(params=afm_params).result\n",
    "\n",
    "    ljff = shelljob(\n",
    "        command=\"ppafm-generate-ljff\",\n",
    "        nodes={\n",
    "            \"geometry\": geometry_file,\n",
    "            \"parameters\": afm_params_file,\n",
    "        },\n",
    "        arguments=[\n",
    "            \"-i\",\n",
    "            \"geo.xyz\",\n",
    "            \"-f\",\n",
    "            \"npy\",\n",
    "        ],\n",
    "        outputs=[\"FFLJ.npz\"],\n",
    "    )\n",
    "\n",
    "    scan_nodes = {\n",
    "        \"parameters\": afm_params_file,\n",
    "        \"ljff_data\": ljff.FFLJ_npz,\n",
    "    }\n",
    "\n",
    "    metadata = {\n",
    "        \"options\": {\n",
    "            \"use_symlinks\": True,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if case != AfmCase.EMPIRICAL.name:\n",
    "        if not relax:\n",
    "            assert dft_params, \"Missing DFT parameters\"\n",
    "            geom_dft_params = dft_params.get(\"geom\", {})\n",
    "            geom_dft_params[\"relax_type\"] = orm.Str(\"none\")\n",
    "            dft_job = DftJob(\n",
    "                engine=engine,\n",
    "                structure=structure,\n",
    "                parameters=geom_dft_params,\n",
    "            )\n",
    "\n",
    "        assert pp_params, \"Missing post-processing parameters\"\n",
    "        hartree_params = pp_params.get(\"hartree_potential\", {})\n",
    "        assert hartree_params, \"Missing Hartree potential post-processing parameters\"\n",
    "        hartree_task = PpJob(\n",
    "            engine=engine,\n",
    "            parent_folder=dft_job.remote_folder,\n",
    "            parameters=hartree_params,\n",
    "        )\n",
    "\n",
    "        if case == AfmCase.HARTREE.name:\n",
    "            elff = shelljob(\n",
    "                command=\"ppafm-generate-elff\",\n",
    "                metadata=metadata,\n",
    "                nodes={\n",
    "                    \"parameters\": afm_params_file,\n",
    "                    \"ljff_data\": ljff.FFLJ_npz,\n",
    "                    \"hartree_data\": hartree_task.remote_folder,\n",
    "                },\n",
    "                filenames={\n",
    "                    \"hartree_data\": \"hartree\",\n",
    "                },\n",
    "                arguments=[\n",
    "                    \"-i\",\n",
    "                    \"hartree/aiida.fileout\",\n",
    "                    \"-F\",\n",
    "                    \"cube\",\n",
    "                    \"-f\",\n",
    "                    \"npy\",\n",
    "                ],\n",
    "                outputs=[\"FFel.npz\"],\n",
    "            )\n",
    "\n",
    "            scan_nodes[\"elff_data\"] = elff.FFel_npz\n",
    "\n",
    "        # Experimental feature, not fully tested\n",
    "        elif case == AfmCase.HARTREE_RHO.name:\n",
    "            charge_params = pp_params.get(\"charge_density\", {})\n",
    "            assert charge_params, \"Missing charge density post-processing parameters\"\n",
    "            rho_job = PpJob(\n",
    "                engine=engine,\n",
    "                parent_folder=dft_job.remote_folder,\n",
    "                parameters=charge_params,\n",
    "            )\n",
    "\n",
    "            assert tip, \"Missing tip structure\"\n",
    "            tip_dft_params = dft_params.get(\"tip\", {})\n",
    "            assert tip_dft_params, \"Missing tip DFT parameters\"\n",
    "            tip_dft_job = DftJob(\n",
    "                engine=engine,\n",
    "                structure=tip,\n",
    "                parameters=tip_dft_params,\n",
    "            )\n",
    "\n",
    "            tip_rho_job = PpJob(\n",
    "                engine=engine,\n",
    "                parent_folder=tip_dft_job.remote_folder,\n",
    "                parameters=charge_params,\n",
    "            )\n",
    "\n",
    "            conv_rho = shelljob(\n",
    "                command=\"ppafm-conv-rho\",\n",
    "                nodes={\n",
    "                    \"geom_density\": rho_job.remote_folder,\n",
    "                    \"tip_density\": tip_rho_job.remote_folder,\n",
    "                },\n",
    "                filenames={\n",
    "                    \"geom_density\": \"structure\",\n",
    "                    \"tip_density\": \"tip\",\n",
    "                },\n",
    "                arguments=[\n",
    "                    \"-s\",\n",
    "                    \"structure/aiida.fileout\",\n",
    "                    \"-t\",\n",
    "                    \"tip/aiida.fileout\",\n",
    "                    \"-B\",\n",
    "                    \"1.0\",\n",
    "                    \"-E\",\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            charge_elff = shelljob(\n",
    "                command=\"ppafm-generate-elff\",\n",
    "                nodes={\n",
    "                    \"conv_rho_data\": conv_rho.remote_folder,\n",
    "                    \"hartree_data\": hartree_task.remote_folder,\n",
    "                    \"tip_density\": tip_rho_job.remote_folder,\n",
    "                },\n",
    "                filenames={\n",
    "                    \"conv_rho_data\": \"conv_rho\",\n",
    "                    \"hartree_data\": \"hartree\",\n",
    "                    \"tip_density\": \"tip\",\n",
    "                },\n",
    "                arguments=[\n",
    "                    \"-i\",\n",
    "                    \"hartree/aiida.fileout\",\n",
    "                    \"-tip-dens\",\n",
    "                    \"tip/aiida.fileout\",\n",
    "                    \"--Rcode\",\n",
    "                    \"0.7\",\n",
    "                    \"-E\",\n",
    "                    \"--doDensity\",\n",
    "                ],\n",
    "                outputs=[\"FFel.npz\"],\n",
    "            )\n",
    "\n",
    "            dftd3 = shelljob(\n",
    "                command=\"ppafm-generate-dftd3\",\n",
    "                nodes={\n",
    "                    \"hartree_data\": hartree_task.remote_folder,\n",
    "                },\n",
    "                filenames={\n",
    "                    \"hartree_data\": \"hartree\",\n",
    "                },\n",
    "                arguments=[\n",
    "                    \"-i\",\n",
    "                    \"hartree/aiida.fileout\",\n",
    "                    \"--df_name\",\n",
    "                    \"PBE\",\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            elff = shelljob(\n",
    "                command=\"ppafm-generate-elff\",\n",
    "                nodes={\n",
    "                    \"hartree_data\": hartree_task.remote_folder,\n",
    "                    \"charge_elff_data\": charge_elff.FFel_npz,\n",
    "                },\n",
    "                filenames={\n",
    "                    \"hartree_data\": \"hartree\",\n",
    "                },\n",
    "                arguments=[\n",
    "                    \"-i\",\n",
    "                    \"hartree/aiida.fileout\",\n",
    "                    \"-f\",\n",
    "                    \"npy\",\n",
    "                ],\n",
    "                outputs=[\"FFel.npz\"],\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported case: {case}\")\n",
    "\n",
    "    scan = shelljob(\n",
    "        command=\"ppafm-relaxed-scan\",\n",
    "        metadata=metadata,\n",
    "        nodes=scan_nodes,\n",
    "        arguments=[\n",
    "            \"-f\",\n",
    "            \"npy\",\n",
    "        ],\n",
    "        outputs=[\"Q0.00K0.35\"],\n",
    "    )\n",
    "\n",
    "    results = shelljob(\n",
    "        command=\"ppafm-plot-results\",\n",
    "        metadata=metadata,\n",
    "        nodes={\n",
    "            \"parameters\": afm_params_file,\n",
    "            \"scan_dir\": scan.Q0_00K0_35,\n",
    "        },\n",
    "        filenames={\n",
    "            \"scan_dir\": \"Q0.00K0.35\",\n",
    "        },\n",
    "        arguments=[\n",
    "            \"--df\",\n",
    "            \"--cbar\",\n",
    "            \"--save_df\",\n",
    "            \"-f\",\n",
    "            \"npy\",\n",
    "        ],\n",
    "        outputs=[\"Q0.00K0.35\"],\n",
    "    )\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c0a2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_pseudo.groups.family.pseudo import PseudoPotentialFamily\n",
    "\n",
    "structure = orm.StructureData()\n",
    "structure.set_cell(\n",
    "    [\n",
    "        [14.9412827110, 0.0, 0.0],\n",
    "        [0.0, 14.5091262213, 0.0],\n",
    "        [0.0, 0.0, 10.0820001747],\n",
    "    ]\n",
    ")\n",
    "structure.set_pbc((False, False, False))\n",
    "structure.append_atom(symbols=\"C\", position=(8.2766055186, 6.1177492411, 5.0595246063))\n",
    "structure.append_atom(symbols=\"C\", position=(8.8582363932, 7.3839854920, 5.0363959612))\n",
    "structure.append_atom(symbols=\"C\", position=(8.0523006568, 8.5208073256, 5.0178902940))\n",
    "structure.append_atom(symbols=\"C\", position=(6.6646772714, 8.3913773689, 5.0224782237))\n",
    "structure.append_atom(symbols=\"C\", position=(6.0830463468, 7.1251409580, 5.0456056988))\n",
    "structure.append_atom(symbols=\"C\", position=(6.8889822232, 5.9883191444, 5.0641114560))\n",
    "structure.append_atom(symbols=\"H\", position=(8.9093056269, 5.2253257080, 5.0739448106))\n",
    "structure.append_atom(symbols=\"H\", position=(9.9475591624, 7.4856249613, 5.0328185108))\n",
    "structure.append_atom(symbols=\"H\", position=(8.5089059407, 9.5148483491, 4.9998780126))\n",
    "structure.append_atom(symbols=\"H\", position=(6.0319773431, 9.2838011020, 5.0080584394))\n",
    "structure.append_atom(symbols=\"H\", position=(4.9937235476, 7.0235011287, 5.0491811392))\n",
    "structure.append_atom(symbols=\"H\", position=(6.4323774593, 4.9942778709, 5.0821221574))\n",
    "\n",
    "tip = orm.StructureData()\n",
    "tip.set_cell(\n",
    "    [\n",
    "        [20.0, 0.0, 0.0],\n",
    "        [0.0, 20.0, 0.0],\n",
    "        [0.0, 0.0, 20.0],\n",
    "    ]\n",
    ")\n",
    "tip.set_pbc((False, False, False))\n",
    "tip.append_atom(symbols=\"C\", position=(0.0, 0.0, 1.15))\n",
    "tip.append_atom(symbols=\"O\", position=(0.0, 0.0, 0.0))\n",
    "\n",
    "kpoints = orm.KpointsData()\n",
    "kpoints.set_kpoints_mesh([1, 1, 1])\n",
    "\n",
    "pseudo_family = t.cast(PseudoPotentialFamily, orm.load_group(4))\n",
    "C_pp = pseudo_family.get_pseudo(\"C\")\n",
    "H_pp = pseudo_family.get_pseudo(\"H\")\n",
    "O_pp = pseudo_family.get_pseudo(\"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c626df",
   "metadata": {},
   "outputs": [],
   "source": [
    "afm_params = {\n",
    "    \"PBC\": False,\n",
    "    \"tip\": \"s\",\n",
    "    \"klat\": 0.3490127886809,\n",
    "    \"krad\": 21.913190531846,\n",
    "    \"gridA\": [14.9412827110, 0.0000000000, 0.0000000000],\n",
    "    \"gridB\": [0.0000000000, 14.5091262213, 0.0000000000],\n",
    "    \"gridC\": [0.0000000000, 0.0000000000, 10.0820001747],\n",
    "    \"sigma\": 0.7,\n",
    "    \"charge\": 0.0,\n",
    "    \"r0Probe\": [0.0, 0.0, 2.97],\n",
    "    \"scanMax\": [14.9412827110, 14.5091262213, 11],\n",
    "    \"scanMin\": [0.0, 0.0, 8],\n",
    "    \"scanStep\": [0.1, 0.1, 0.1],\n",
    "    \"Amplitude\": 1.4,\n",
    "    \"probeType\": \"O\",\n",
    "    \"f0Cantilever\": 22352.5,\n",
    "    \"gridN\": [-1, -1, -1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf33e88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft_params = {\n",
    "    \"geom\": {\n",
    "        \"engines\": {\n",
    "            \"relax\": {\n",
    "                \"code\": orm.load_code(\"pw-7.4@localhost\"),\n",
    "                \"options\": {\n",
    "                    \"resources\": {\n",
    "                        \"num_machines\": 1,\n",
    "                    },\n",
    "                    \"max_wallclock_seconds\": 43200,\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        \"protocol\": \"fast\",\n",
    "        \"relax_type\": \"positions\",\n",
    "    },\n",
    "    \"tip\": {\n",
    "        \"engines\": {\n",
    "            \"relax\": {\n",
    "                \"code\": orm.load_code(\"pw-7.4@localhost\"),\n",
    "                \"options\": {\n",
    "                    \"resources\": {\n",
    "                        \"num_machines\": 1,\n",
    "                    },\n",
    "                    \"max_wallclock_seconds\": 43200,\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        \"protocol\": \"fast\",\n",
    "        \"relax_type\": \"none\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7ffea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_params = {\n",
    "    \"hartree_potential\": {\n",
    "        \"engines\": {\n",
    "            \"pp\": {\n",
    "                \"code\": orm.load_code(\"pp-7.4@localhost\"),\n",
    "                \"options\": {\n",
    "                    \"resources\": {\n",
    "                        \"num_machines\": 1,\n",
    "                    },\n",
    "                    \"max_wallclock_seconds\": 43200,\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        \"quantity\": \"potential\",\n",
    "    },\n",
    "    \"charge_density\": {\n",
    "        \"engines\": {\n",
    "            \"pp\": {\n",
    "                \"code\": orm.load_code(\"pp-7.4@localhost\"),\n",
    "                \"options\": {\n",
    "                    \"resources\": {\n",
    "                        \"num_machines\": 1,\n",
    "                    },\n",
    "                    \"max_wallclock_seconds\": 43200,\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        \"quantity\": \"charge_density\",\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7823b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg = AfmWorkflow.build(\n",
    "    engine=\"quantum_espresso\",\n",
    "    case=AfmCase.HARTREE.name,\n",
    "    structure=structure,\n",
    "    afm_params=afm_params,\n",
    "    relax=False,\n",
    "    dft_params=dft_params,\n",
    "    pp_params=pp_params,\n",
    "    tip=tip,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b467ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baa60aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50fa794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "fd: orm.FolderData\n",
    "if wg.outputs.Q0_00K0_35.value:\n",
    "    fd = wg.outputs.Q0_00K0_35.value\n",
    "else:\n",
    "    node = orm.load_node(wg.pk)\n",
    "    fd = node.outputs.Q0_00K0_35\n",
    "\n",
    "imgs = []\n",
    "\n",
    "png_folder = \"Amp1.40\"\n",
    "\n",
    "for obj in fd.list_objects(png_folder):\n",
    "    if obj.name.endswith(\".png\"):\n",
    "        with fd.open(f\"{png_folder}/{obj.name}\", \"rb\") as handle:\n",
    "            data = handle.read()\n",
    "            data64 = base64.b64encode(data).decode(\"utf-8\")\n",
    "            imgs.append(f\"\"\"\n",
    "                <img\n",
    "                    src=\"data:image/png;base64,{data64}\"\n",
    "                    style=\"max-width:150px; margin:5px;\"\n",
    "                />\n",
    "            \"\"\")\n",
    "\n",
    "HTML(\"\".join(imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238f1c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
